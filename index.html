<!DOCTYPE HTML>
<html lang="en">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>Ryan Zeyuan Chen</title>
  <meta name="author" content="Ryan Zeyuan Chen">
  <meta name="keywords" content="Ryan Zeyuan Chen; Ryan Chen; Soft Robotics; Continuum Robotics; Univeristy of Toronto; Engineering Science; U of T EngSci">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="google-site-verification" content="tNUEmiM3cUyO7KtojOjL2uDm23o0-C2TkRYfj2_OcXA" />
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/icon.png">
</head>

<body>
  <div class ="background "id="vanta"></div>
  <script src="three.r119.min.js"></script>
  <script src="vanta.net.min.js"></script>
  <script>
  VANTA.NET({
    el: "#vanta",
    mouseControls: true,
    touchControls: true,
    gyroControls: false,
    minHeight: 200.00,
    minWidth: 200.00,
    scale: 1.00,
    scaleMobile: 1.00,
    color: 0xdedede,
    backgroundColor: 0xffffff,
    points: 8.00,
    // maxDistance:15.00,
    spacing: 20.00
  })
  </script>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;background-color:#f9f9f9;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Ryan Zeyuan Chen</name>
              </p>
              <p>I am a first year <strong>Mechanical Engineering MASc</strong> student at the University of Toronto. I am advised by <a href="https://www.mie.utoronto.ca/faculty_staff/goldenberg/">Andrew Goldenberg</a> and a member of the <a href="https://ral.mie.utoronto.ca/">Robotics and Automation Laboratory</a>.
              </p>
              <p>
                I have previously completed my <strong>Undergraduate Thesis</strong> at the <a href="https://crl.utm.utoronto.ca/">Continuum Robotics Laboratory</a> under the supervision of <a href="https://crl.utm.utoronto.ca/jbk.html">Jessica Burgner-Kahrs</a> of the <a href="https://robotics.utoronto.ca/">University of Toronto Robotics Institute</a>. I was formerly a <strong>Research Assistant</strong> at the <a href="https://liulab.mie.utoronto.ca/">Microfluidics and BioMEMS Laboratory</a> with the guidance of <a href="https://www.mie.utoronto.ca/faculty_staff/xinyu-liu/">Xinyu Liu</a>. I have also completed a one-year <strong>SerDes Application Design Internship</strong> at <a href="https://www.xilinx.com/">Xilinx</a> in the industry.
              </p>
              <p style="text-align:center">
                <a href="mailto:ryanchen0614@gmail.com">Email</a> &nbsp/&nbsp
                <a href="data/Ryan_Zeyuan_Chen_CV.pdf">CV</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/ryan-zeyuan-chen/">LinkedIn</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=AUVj0LYAAAAJ">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/ryan-zeyuan-chen">GitHub</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/Ryan_Square.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/Ryan_Circle.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Education</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/UofT_Square.jpg' width="160">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>M.A.Sc. in Mechanical Engineering</papertitle>
              <br>
              Faculty of Applied Science and Engineering, University of Toronto
              <br>
              Sep 2022 - Ongoing | Toronto, ON, Canada
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/UofT_Square.jpg' width="160">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>B.A.Sc. in Engineering Science, Robotics Engineering</papertitle>
              <br>
              Faculty of Applied Science and Engineering, University of Toronto
              <br>
              Sep 2017 - Apr 2022 | Toronto, ON, Canada
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                I am interested in the <strong>sensing</strong>, <strong>modeling</strong>, and <strong>control</strong> of medical and soft robots utilizing <strong>machine learning</strong>. Compared to the rigid mechanical structure of conventional robots, the inherent compliance and flexibility of soft robots enable them to travel in confined spaces and manipulate objects in complex environments. In medical applications, such robots allow clinicians to deliver less invasive treatments at a reduced cost and higher efficiency.
              </p>
              <p>
                My current research focuses on <strong>AI-embedded robotics in medical applications</strong>, specifically AI-embedded control of concentric tube continuum robots in surgical applications.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <subheading>Journal Papers</subheading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/AFM.jpg' width="160">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://onlinelibrary.wiley.com/doi/10.1002/adfm.202104665">
                <papertitle>An Anti-freezing, Ambient-Stable and Highly Stretchable Ionic Skin with Strong Surface Adhesion for Wearable Sensing and Soft Robotics</papertitle>
              </a>
              <br>
              <a href="http://binbinying.weebly.com/">Binbin Ying</a>,
              <strong>Ryan Zeyuan Chen</strong>,
              <a href="https://www.runzezuo.com/">Runze Zuo</a>,
              <a href="https://www.mcgill.ca/mecheng/jianyu-li">Jianyu Li</a>,
              <a href="https://www.mie.utoronto.ca/faculty_staff/xinyu-liu/">Xinyu Liu</a>
              <br>
              <em>Advanced Functional Materials</em>, 2021
              <br>
              Videos: <a href="https://onlinelibrary.wiley.com/action/downloadSupplement?doi=10.1002%2Fadfm.202104665&file=adfm202104665-sup-0008-MovieS7.mp4">HMI</a>, <a href="https://onlinelibrary.wiley.com/action/downloadSupplement?doi=10.1002%2Fadfm.202104665&file=adfm202104665-sup-0014-MovieS13.mp4">Soft Robot</a> /
              News: <a href="https://www.utoronto.ca/news/researchers-develop-stretchable-sensor-material-power-wearable-electronics-and-it-works-extreme">U of T News</a>, <a href="https://news.engineering.utoronto.ca/iskin-the-cold-tolerant-stretchable-sticky-sensor-that-could-power-a-new-generation-of-wearable-electronics-and-more/">U of T Engineering News</a>
              <p>A novel hydrogel-based ionic skin (iSkin) capable of strain sensing is demonstrated with high toughness, high stretchability, excellent ambient stability, superior anti-freezing capability, and strong surface adhesion. This work also provides a new paradigm for developing high-performance artificial skins for wearable sensing and soft robotics.</p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <subheading>Conference Papers</subheading>
            </td>
          </tr>
        </tbody></table>
        <!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/CTCR.jpg' width="160">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Learning-Based Differential Inverse Kinematics for Concentric Tube Continuum Robots</papertitle>
              <br>
              <strong>Ryan Zeyuan Chen</strong>,
              <a href="https://scholar.google.com/citations?user=6nbw0sgAAAAJ">Reinhard M. Grassmann</a>,
              <a href="https://crl.utm.utoronto.ca/jbk.html">Jessica Burgner-Kahrs</a>
              <br>
              <em>Manuscript in Preparation</em>, 2022
              <br>
              <p>This work introduces an approach to obtain the inverse kinematics of concentric tube continuum robots through the application of differential inverse kinematics based on a learned forward kinematics model.</p>
            </td>
          </tr>
        </tbody></table> -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/Dataset.png' width="160">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/abstract/document/9981719">
                <papertitle>A Dataset and Benchmark for Learning the Kinematics of Concentric Tube Continuum Robots</papertitle>
              </a>
              <br>
              <a href="https://scholar.google.com/citations?user=6nbw0sgAAAAJ">Reinhard M. Grassmann</a>,
              <strong>Ryan Zeyuan Chen</strong>,
              <a href="https://scholar.google.ca/citations?user=0h1At3cAAAAJ">Nan Liang</a>,
              <a href="https://crl.utm.utoronto.ca/jbk.html">Jessica Burgner-Kahrs</a>
              <br>
              <em>Workshop on Learning from Diverse, Offline Data (L-DOD)</em>, 2022
              <br>
              <em>IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</em>, 2022
              <br>
              <a href="https://ieeexplore.ieee.org/abstract/document/9981719">IROS</a> /
              <a href="https://openreview.net/forum?id=DW9uz_GZ0og">RSS L-DOD</a> /
              <a href="https://github.com/ContinuumRoboticsLab/CRL-Dataset-CTCR-Pose">Dataset</a>
              <p>This work presents a dataset captured from a three-tube concentric tube continuum robot (CTCR) for use in learning-based kinematics research. Insights and lessons learned on joint space representation, shape representation in task space, and sampling strategies are shared as well. Furthermore, benchmark results for learning the forward kinematics using a simple, shallow feedforward neural network are provided.</p>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Projects</heading>
              <p>
                I have worked on a wide range of interesting projects in the fields of <strong>robotics</strong> and <strong>machine learning</strong>.
                <br>
                These opportunities broadened my perspective and provided me with a holistic vision of the robotics field.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/MIE1075.png' width="160">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Intelligent Dog Walking Robot</papertitle>
              <br>
                MIE1075 Artificial Intelligence for Robotics I, University of Toronto
              <br>
              <a href="data/MIE1075.pdf">Final Report</a> /
              <a href="https://github.com/ryan-zeyuan-chen/MIE1075">Code</a>
              <p>The design and implementation of an intelligent dog walking robot with real-time visual dog tracking, dog following, and dog waste disposal capabilities.</p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/ROB498.png' width="160">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Intelligent Robotic Shopping Cart</papertitle>
              <br>
                ROB498 Robotics Capstone Design, University of Toronto
              <br>
              <a href="data/ROB498.pdf">Final Report</a> /
              <a href="data/ROB498.mp4">Presentation</a>
              <p>The design and implementation of an intelligent robotic shopping cart with customer following, shopping guide, and auto-checkout features.</p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/MIE505.png' width="160">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Independent Control of Three Magnetic Microrobots in Three Dimensions</papertitle>
              <br>
                MIE505 Micro/Nano Robotics, University of Toronto
              <br>
              <a href="data/MIE505.pdf">Final Report</a> /
              <a href="data/MIE505_Literature_Review.pdf">Literature Review</a>
              <p>The development of a robust control strategy to independently control three magnetic microrobots in a three-dimensional workspace.</p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/APS360.png' width="160">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://github.com/ryan-zeyuan-chen/wine">
                <papertitle>Deep Learning Wine Grape Variety Recognition</papertitle>
              </a>
              <br>
              <a href="https://ryan-zeyuan-chen.github.io/APS360/">APS360 Applied Fundamentals of Machine Learning</a>, University of Toronto
              <br>
              <a href="data/APS360.pdf">Final Report</a> /
              <a href="data/APS360.mp4">Presentation</a>
              <p>The recognition of wine grape variety through wine taste descriptions utilizing the long short-term memory (LSTM) deep learning model.</p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/MIE438.jpeg' width="160">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Gesture Controlled Claw Machine</papertitle>
              <br>
                MIE438 Microcontrollers and Embedded Microprocessors, University of Toronto
              <br>
              <a href="data/MIE438.pdf">Final Report</a>
              <p>The design of a gesture controlled claw machine utilizing a wearable device instead of traditional joystick control (unable to physically implement due to COVID-19 restrictions).</p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/RoboSoccer.jpg' width="160">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="http://utrahumanoid.ca/">
                <papertitle>RoboSoccer</papertitle>
              </a>
              <br>
                <a href="https://www.utra.ca/">University of Toronto Robotics Association</a>
              <br>
              <a href="https://github.com/utra-robosoccer">Code</a> /
              <a href="https://www.robocup.org/">Competition</a> /
              Videos: <a href="https://www.youtube.com/watch?v=OsnoJQtPXjM">RoboCup 2020</a>, <a href="https://www.youtube.com/watch?v=vKF9ddF4Gi8">Getting Up</a>, <a href="https://www.youtube.com/watch?v=KY-j0H8Yqi0">Backflip</a>
              <p>Developed embedded software for the humanoid robot in C++, documented using Doxygen, and using FreeRTOS to provide multithreading capabilities.</p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/Pacbot.jpg' width="160">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://www.utra.ca/teams/pacbot/">
                <papertitle>Pacbot</papertitle>
              </a>
              <br>
                <a href="https://www.utra.ca/">University of Toronto Robotics Association</a>
              <br>
              <a href="https://harvardrobotics.com/pacbots#pacbotinfo">Competition</a>
              <p>Organized and led weekly meetings with subteam members focusing on the design and implementation of circuits and sensors for the autonomous robot.</p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/ROB301.png' width="160">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://github.com/ryan-zeyuan-chen/ROB301/blob/master/Final_Design_Project/README.md">
                <papertitle>The Galbraith Memorial Mail Robot</papertitle>
              </a>
              <br>
                <a href="https://github.com/ryan-zeyuan-chen/ROB301">ROB301 Introduction to Robotics</a>, University of Toronto
              <br>
              <a href="data/ROB301.pdf">Final Report</a> /
              <a href="https://github.com/ryan-zeyuan-chen/ROB301/tree/master/Final_Design_Project">Code</a>
              <p>The design of a control system, based on Bayesian-localization techniques, for the TurtleBot 3 Waffle Pi robot to deliver mail to arbitrarily chosen stations on a closed-loop route.</p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/AER201.jpg' width="160">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ryan-zeyuan-chen.github.io/AER201/">
                <papertitle>Traffic Cone Deployment Robot</papertitle>
              </a>
              <br>
                <a href="http://aer201.aerospace.utoronto.ca/">AER201 Engineering Design</a>, University of Toronto
              <br>
              <a href="data/AER201.pdf">Final Report</a> /
              <a href="data/AER201.mp4">Video</a>
              <p>The design and fabrication of a scaled-down, proof-of-concept prototype of a mobile platform that can travel along a designated lane and deploy traffic cones.</p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
  <div align="center" style="margin:auto;padding-top:10px">
      <div style="width:10%">
        <script type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=r5YSPPdQLM-bqjYKB-ZUojvF8CrcJkbDpRsawEGPPwU"></script>
      </div>
  </div>
</body>

</html>
